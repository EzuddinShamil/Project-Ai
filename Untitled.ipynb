{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EzuddinShamil/Project-Ai/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b26d0ba6-db8a-4e28-be98-c4a70f2c0d66",
      "metadata": {
        "id": "b26d0ba6-db8a-4e28-be98-c4a70f2c0d66"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense,Flatten,BatchNormalization,Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBuuZDxG0Msa",
        "outputId": "2a21c920-26ad-4464-d4f3-4a2d78065a5b"
      },
      "id": "IBuuZDxG0Msa",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/My Drive/Colab Notebooks/dataset/train'\n",
        "valid_path = '/content/drive/My Drive/Colab Notebooks/dataset/val'\n",
        "test_path = '/content/drive/My Drive/Colab Notebooks/dataset/test'"
      ],
      "metadata": {
        "id": "h8OdcMFm0U3m"
      },
      "id": "h8OdcMFm0U3m",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
        "train_batches = ImageDataGenerator(preprocessing_function=preprocess_input) \\\n",
        "                   .flow_from_directory(directory=train_path, target_size=(180,180), classes=['Capybara','Cat','dog'], batch_size = 10)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=preprocess_input) \\\n",
        "                   .flow_from_directory(directory=valid_path, target_size=(180,180), classes=['Capybara','Cat','dog'], batch_size = 10)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=preprocess_input) \\\n",
        "                   .flow_from_directory(directory=test_path, target_size=(180,180), classes=['Capybara','Cat','dog'], batch_size = 10, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVG_ED5w04lw",
        "outputId": "6b3a70d7-3b52-4264-fe21-ea42455eb716"
      },
      "id": "GVG_ED5w04lw",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 3 classes.\n",
            "Found 10000 images belonging to 3 classes.\n",
            "Found 10000 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d118b6f1-cbc5-4136-b9cf-2ac893cd8308",
      "metadata": {
        "id": "d118b6f1-cbc5-4136-b9cf-2ac893cd8308"
      },
      "outputs": [],
      "source": [
        "assert train_batches.n == 10000\n",
        "assert valid_batches.n == 10000\n",
        "assert test_batches.n == 10000\n",
        "assert train_batches.num_classes == valid_batches.num_classes == test_batches.num_classes == 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1a163bb6-2eb2-49b0-893a-3bddce2960b9",
      "metadata": {
        "id": "1a163bb6-2eb2-49b0-893a-3bddce2960b9"
      },
      "outputs": [],
      "source": [
        "imgs , labels = next(train_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d2815682-ebea-4b6f-9d9e-4846bd3b2732",
      "metadata": {
        "id": "d2815682-ebea-4b6f-9d9e-4846bd3b2732"
      },
      "outputs": [],
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 10, figsize = (20, 20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr,axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3b757358-a463-4bc3-8503-476443eb05c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "3b757358-a463-4bc3-8503-476443eb05c3",
        "outputId": "17660386-18b6-4ccc-d73c-93e9335e9c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..236.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [6.0..183.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [5.0..255.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [6.0..254.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [6.0..254.0].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "plotImages(imgs)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8ce957da-7602-45ba-8780-01e409004ced",
      "metadata": {
        "id": "8ce957da-7602-45ba-8780-01e409004ced"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "\n",
        "# Create a Sequential model\n",
        "mobilev3_model = Sequential()\n",
        "\n",
        "# Instantiate MobileNetV3Large as the base model\n",
        "pretrained_model = MobileNetV3Large(\n",
        "    input_shape=(180, 180, 3),\n",
        "    alpha=1.0,\n",
        "    minimalistic=False,\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    classes=3,\n",
        "    pooling='avg',\n",
        "    dropout_rate=0.2,\n",
        "    classifier_activation=\"softmax\",\n",
        "    include_preprocessing=True,\n",
        ")\n",
        "\n",
        "# Make all layers in the base model trainable\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add the base model to the Sequential model\n",
        "mobilev3_model.add(pretrained_model)\n",
        "\n",
        "# Add your classification layers\n",
        "mobilev3_model.add(Flatten())\n",
        "mobilev3_model.add(Dense(512, activation='relu'))\n",
        "mobilev3_model.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d519639c-0122-4cf9-b482-1a8cf4da8f38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "d519639c-0122-4cf9-b482-1a8cf4da8f38",
        "outputId": "957c61d3-17cf-40fb-dce8-5bfd54a1ebcb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)                 │       \u001b[38;5;34m2,996,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m492,032\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">492,032</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,489,923\u001b[0m (13.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,489,923</span> (13.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,465,523\u001b[0m (13.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,465,523</span> (13.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,400\u001b[0m (95.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,400</span> (95.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "mobilev3_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a84c6e-fe96-46fb-867b-cb549c6228ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0a84c6e-fe96-46fb-867b-cb549c6228ea",
        "outputId": "a6d5029e-f031-42ac-bb10-caaff57491be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m 280/1000\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21:39\u001b[0m 2s/step - accuracy: 0.9150 - loss: 0.2589"
          ]
        }
      ],
      "source": [
        "mobilev3_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 50\n",
        "history = mobilev3_model.fit(\n",
        "    train_batches,\n",
        "    validation_data=valid_batches,\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = ImageDataGenerator(preprocessing_function=preprocess_input) \\\n",
        "                        .flow_from_directory(directory=train_path, target_size=(180, 180), classes=['Capybara','Cat','dog'], batch_size = 10)\n",
        "     valid_batches = ImageDataGenerator(preprocessing_function=preprocess_input) \\\n",
        "                        .flow_from_directory(directory=valid_path, target_size=(180, 180), classes=['Capybara','Cat','dog'], batch_size = 10)\n",
        "     test_batches = ImageDataGenerator(preprocessing_function=preprocess_input) \\\n",
        "                        .flow_from_directory(directory=test_path, target_size=(180, 180), classes=['Capybara','Cat','dog'], batch_size = 10, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "A_h9v1En20rB",
        "outputId": "c25a1da6-9807-43af-bdd4-5eba57e0a135"
      },
      "id": "A_h9v1En20rB",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-18-d060497a9cb3>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-d060497a9cb3>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    valid_batches = ImageDataGenerator(preprocessing_function=preprocess_input) \\\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = tf.keras.applications.MobileNetV3Large(\n",
        "         input_shape=(224, 224, 3),  # Change input shape here\n",
        "         alpha=1.0,\n",
        "         minimalistic=False,\n",
        "         include_top=False,\n",
        "         weights=\"imagenet\",\n",
        "         classes=3,\n",
        "         pooling='avg',\n",
        "         dropout_rate=0.2,\n",
        "         classifier_activation=\"softmax\",\n",
        "         include_preprocessing=True,\n",
        "     )"
      ],
      "metadata": {
        "id": "9JuPPsze2t5E"
      },
      "id": "9JuPPsze2t5E",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ffaf593-e43c-498d-80da-324825fd78fb",
      "metadata": {
        "id": "9ffaf593-e43c-498d-80da-324825fd78fb",
        "outputId": "ac78920e-dc43-4a2b-ca46-7aae829688e8"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] The system cannot find the path specified: 'path_to_training_data'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m      4\u001b[0m valid_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m train_batches \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_training_data\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m180\u001b[39m),  \u001b[38;5;66;03m# Resize images\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     10\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m valid_batches \u001b[38;5;241m=\u001b[39m valid_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_validation_data\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m180\u001b[39m),  \u001b[38;5;66;03m# Resize images\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     17\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m )\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m ):\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1139\u001b[0m         directory,\n\u001b[0;32m   1140\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1141\u001b[0m         target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[0;32m   1142\u001b[0m         color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[0;32m   1143\u001b[0m         keep_aspect_ratio\u001b[38;5;241m=\u001b[39mkeep_aspect_ratio,\n\u001b[0;32m   1144\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m   1145\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[0;32m   1146\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[0;32m   1147\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1148\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   1149\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m   1150\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m   1151\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m   1152\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m   1153\u001b[0m         follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m   1154\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m   1155\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   1156\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1157\u001b[0m     )\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'path_to_training_data'"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_batches = train_datagen.flow_from_directory(\n",
        "    'path_to_training_data',\n",
        "    target_size=(180, 180),  # Resize images\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_batches = valid_datagen.flow_from_directory(\n",
        "    'path_to_validation_data',\n",
        "    target_size=(180, 180),  # Resize images\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "800a7232-b2ac-44e4-9287-fd4ae2cc8480",
      "metadata": {
        "id": "800a7232-b2ac-44e4-9287-fd4ae2cc8480",
        "outputId": "9f36871b-182b-4f9a-8621-d7dbfb572779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 3 classes.\n",
            "Found 10000 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_batches = train_datagen.flow_from_directory(\n",
        "    'C:/Users/EZUDDIN/Documents/dataset/train',\n",
        "    target_size=(180, 180),  # Resize images\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_batches = valid_datagen.flow_from_directory(\n",
        "    'C:/Users/EZUDDIN/Documents/dataset/val',\n",
        "    target_size=(180, 180),  # Resize images\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fccff03-a6ef-42c2-b4de-3ca633c653aa",
      "metadata": {
        "id": "6fccff03-a6ef-42c2-b4de-3ca633c653aa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "\n",
        "base_model = MobileNetV3Large(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3fa7a3f-c48d-4c88-a387-193136ff2ce3",
      "metadata": {
        "id": "e3fa7a3f-c48d-4c88-a387-193136ff2ce3",
        "outputId": "ae6fe30d-84f4-4041-ed3c-f7c5ab3d7405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 2s/step - accuracy: 0.9686 - loss: 0.0938 - val_accuracy: 0.2823 - val_loss: 4.2526\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 2s/step - accuracy: 0.9920 - loss: 0.0341 - val_accuracy: 0.3000 - val_loss: 2.3084\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.4731e-05 - val_accuracy: 0.3068 - val_loss: 2.0535\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.4410e-06 - val_accuracy: 0.2174 - val_loss: 2.1732\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 2s/step - accuracy: 0.9990 - loss: 0.0045 - val_accuracy: 0.2000 - val_loss: 410.6326\n",
            "Epoch 6/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 2s/step - accuracy: 0.9843 - loss: 0.0989 - val_accuracy: 0.2000 - val_loss: 55.5702\n",
            "Epoch 7/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 0.9998 - loss: 5.0318e-04 - val_accuracy: 0.2000 - val_loss: 66.2354\n",
            "Epoch 8/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.1400e-05 - val_accuracy: 0.2000 - val_loss: 64.6098\n",
            "Epoch 9/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.8456e-05 - val_accuracy: 0.2000 - val_loss: 47.3233\n",
            "Epoch 10/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 2s/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.3067 - val_loss: 19.2900\n",
            "Epoch 11/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 2s/step - accuracy: 0.9940 - loss: 0.0325 - val_accuracy: 0.2000 - val_loss: 4.4387\n",
            "Epoch 12/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 2s/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.2760 - val_loss: 2.5133\n",
            "Epoch 13/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 2s/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.2000 - val_loss: 15.3850\n",
            "Epoch 14/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 2s/step - accuracy: 0.9998 - loss: 2.2266e-04 - val_accuracy: 0.2000 - val_loss: 9.4245\n",
            "Epoch 15/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.9515e-05 - val_accuracy: 0.2129 - val_loss: 6.3193\n",
            "Epoch 16/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.1785e-06 - val_accuracy: 0.3227 - val_loss: 3.5121\n",
            "Epoch 17/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.3072e-06 - val_accuracy: 0.5647 - val_loss: 1.9036\n",
            "Epoch 18/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.1023e-06 - val_accuracy: 0.8001 - val_loss: 0.8484\n",
            "Epoch 19/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.2597e-06 - val_accuracy: 0.9153 - val_loss: 0.3338\n",
            "Epoch 20/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.0379e-06 - val_accuracy: 0.9750 - val_loss: 0.0798\n",
            "Epoch 21/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.1550e-06 - val_accuracy: 0.9917 - val_loss: 0.0227\n",
            "Epoch 22/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.3964e-06 - val_accuracy: 1.0000 - val_loss: 7.3369e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.6396e-07 - val_accuracy: 1.0000 - val_loss: 5.6526e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.0649e-07 - val_accuracy: 1.0000 - val_loss: 1.3347e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.8879e-07 - val_accuracy: 1.0000 - val_loss: 3.7551e-06\n",
            "Epoch 26/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.3779e-07 - val_accuracy: 1.0000 - val_loss: 1.2966e-06\n",
            "Epoch 27/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.6080e-07 - val_accuracy: 1.0000 - val_loss: 6.3372e-07\n",
            "Epoch 28/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.5204e-07 - val_accuracy: 1.0000 - val_loss: 1.4233e-07\n",
            "Epoch 29/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.7084e-07 - val_accuracy: 1.0000 - val_loss: 5.0115e-08\n",
            "Epoch 30/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.5001e-08 - val_accuracy: 1.0000 - val_loss: 5.6386e-09\n",
            "Epoch 31/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.9223e-07 - val_accuracy: 1.0000 - val_loss: 1.5497e-09\n",
            "Epoch 32/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.1696e-08 - val_accuracy: 1.0000 - val_loss: 4.0531e-10\n",
            "Epoch 33/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.0497e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 34/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.2323e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 35/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.6501e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 36/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.7114e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 37/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.8074e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 38/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.0744e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 39/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.6558e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 40/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.1673e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 41/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.2308e-08 - val_accuracy: 1.0000 - val_loss: 1.2204e-06\n",
            "Epoch 42/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.2323e-08 - val_accuracy: 1.0000 - val_loss: 1.7711e-07\n",
            "Epoch 43/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.2940e-08 - val_accuracy: 1.0000 - val_loss: 2.7466e-08\n",
            "Epoch 44/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.5631e-08 - val_accuracy: 1.0000 - val_loss: 3.3617e-09\n",
            "Epoch 45/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.3325e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 46/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.9050e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 47/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.9316e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 48/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.5304e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 49/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.6194e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 50/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.5919e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "resnet_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 50\n",
        "history = resnet_model.fit(\n",
        "    train_batches,\n",
        "    validation_data=valid_batches,\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e786d6e-005d-4f0d-b903-b28d94d0a312",
      "metadata": {
        "id": "5e786d6e-005d-4f0d-b903-b28d94d0a312",
        "outputId": "0b6d5c3a-d2bc-4989-dc9e-9479f3836c39"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m fig1\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mgcf()\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(ymin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,ymax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig1=plt.gcf()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4e682fe-17fc-48d9-89c8-4ff0d2e4f82d",
      "metadata": {
        "id": "a4e682fe-17fc-48d9-89c8-4ff0d2e4f82d"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.grid()\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75660cbb-1924-41e9-ae11-ca7f9d1c4640",
      "metadata": {
        "id": "75660cbb-1924-41e9-ae11-ca7f9d1c4640"
      },
      "outputs": [],
      "source": [
        "test_imgs, test_labels = next(test_batches)\n",
        "plotImages(test_imgs)\n",
        "print(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9534ea35-1570-4f72-972d-443502fef424",
      "metadata": {
        "id": "9534ea35-1570-4f72-972d-443502fef424"
      },
      "outputs": [],
      "source": [
        "test_batches.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28e2199b-e963-4618-95a4-83e38cf1be8e",
      "metadata": {
        "id": "28e2199b-e963-4618-95a4-83e38cf1be8e"
      },
      "outputs": [],
      "source": [
        "predictions = resnet_model.predict(x=test_batches, verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314b3063-968a-4487-a56a-4e22d7bc6618",
      "metadata": {
        "id": "314b3063-968a-4487-a56a-4e22d7bc6618"
      },
      "outputs": [],
      "source": [
        "np.round(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b172b069-f57a-4ed2-9681-d1b908ebb966",
      "metadata": {
        "id": "b172b069-f57a-4ed2-9681-d1b908ebb966"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis = -1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1731069b-6f24-48a6-9264-63cf3edfa61b",
      "metadata": {
        "id": "1731069b-6f24-48a6-9264-63cf3edfa61b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a75bd1-8fa4-49f4-9fbd-57884390be6f",
      "metadata": {
        "id": "77a75bd1-8fa4-49f4-9fbd-57884390be6f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}